{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:15:39.960281Z",
     "start_time": "2020-05-29T10:15:39.953300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Flatten,Dense,Input,Dropout,BatchNormalization\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:15:12.949567Z",
     "start_time": "2020-05-29T10:15:12.908637Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_origin = pd.read_csv('../data/featured_data/X_train.csv')\n",
    "y_train_origin = pd.read_csv('../data/featured_data/y_train.csv')\n",
    "\n",
    "y_train_no_log = np.expm1(y_train_origin)\n",
    "\n",
    "X_train_origin = X_train_origin.to_numpy()\n",
    "y_train_no_log = y_train_no_log.to_numpy()\n",
    "y_train_no_log = y_train_no_log.ravel()\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_origin, y_train_no_log, test_size=0.2, random_state=1) \n",
    "input_dim=X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:15:14.923290Z",
     "start_time": "2020-05-29T10:15:12.951556Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=input_dim, activation='elu',kernel_initializer='he_normal', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(32, activation='elu',kernel_initializer='he_normal', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:15:42.094604Z",
     "start_time": "2020-05-29T10:15:42.090583Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch=300\n",
    "\n",
    "# performance decay scheduling\n",
    "# lr = lr*0.5 if val_loss does not decrease in 5 consequtive epochs\n",
    "# can work with Adam\n",
    "lr_scheduler_pfm = ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "# save the model when the performance on val is the best\n",
    "checkpoint_callback = ModelCheckpoint('../models/best_NN.h5', save_best_only=True)\n",
    "\n",
    "# stop train when there is no progress in 10 consequtive epochs\n",
    "early_stop_callback = EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:16:45.470780Z",
     "start_time": "2020-05-29T10:16:02.627263Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1168 samples, validate on 292 samples\n",
      "Epoch 1/300\n",
      "1168/1168 [==============================] - 1s 1ms/sample - loss: 182208.0685 - val_loss: 175770.6254\n",
      "Epoch 2/300\n",
      "1168/1168 [==============================] - 0s 111us/sample - loss: 182203.8480 - val_loss: 175765.3183\n",
      "Epoch 3/300\n",
      "1168/1168 [==============================] - 0s 109us/sample - loss: 182195.9454 - val_loss: 175754.9944\n",
      "Epoch 4/300\n",
      "1168/1168 [==============================] - 0s 105us/sample - loss: 182180.5060 - val_loss: 175735.4037\n",
      "Epoch 5/300\n",
      "1168/1168 [==============================] - 0s 111us/sample - loss: 182151.9694 - val_loss: 175700.8467\n",
      "Epoch 6/300\n",
      "1168/1168 [==============================] - 0s 103us/sample - loss: 182103.0424 - val_loss: 175643.4632\n",
      "Epoch 7/300\n",
      "1168/1168 [==============================] - 0s 109us/sample - loss: 182025.9369 - val_loss: 175556.4882\n",
      "Epoch 8/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 181912.0670 - val_loss: 175432.7838\n",
      "Epoch 9/300\n",
      "1168/1168 [==============================] - 0s 149us/sample - loss: 181754.5920 - val_loss: 175265.9244\n",
      "Epoch 10/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 181545.1537 - val_loss: 175046.8348\n",
      "Epoch 11/300\n",
      "1168/1168 [==============================] - 0s 124us/sample - loss: 181277.6269 - val_loss: 174775.6729\n",
      "Epoch 12/300\n",
      "1168/1168 [==============================] - 0s 122us/sample - loss: 180946.2708 - val_loss: 174441.2896\n",
      "Epoch 13/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 180543.8771 - val_loss: 174038.3863\n",
      "Epoch 14/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 180061.6177 - val_loss: 173562.6109\n",
      "Epoch 15/300\n",
      "1168/1168 [==============================] - 0s 125us/sample - loss: 179495.5743 - val_loss: 173007.2074\n",
      "Epoch 16/300\n",
      "1168/1168 [==============================] - 0s 155us/sample - loss: 178842.9015 - val_loss: 172368.9131\n",
      "Epoch 17/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 178093.1667 - val_loss: 171649.6002\n",
      "Epoch 18/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 177248.7909 - val_loss: 170834.7926\n",
      "Epoch 19/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 176292.5548 - val_loss: 169919.5571\n",
      "Epoch 20/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 175231.2173 - val_loss: 168910.6871\n",
      "Epoch 21/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 174057.8609 - val_loss: 167788.9003\n",
      "Epoch 22/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 172767.4996 - val_loss: 166568.5828\n",
      "Epoch 23/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 171356.0458 - val_loss: 165237.2491\n",
      "Epoch 24/300\n",
      "1168/1168 [==============================] - 0s 124us/sample - loss: 169817.0886 - val_loss: 163786.1680\n",
      "Epoch 25/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 168144.2545 - val_loss: 162219.4080\n",
      "Epoch 26/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 166336.5638 - val_loss: 160522.9942\n",
      "Epoch 27/300\n",
      "1168/1168 [==============================] - 0s 122us/sample - loss: 164387.9555 - val_loss: 158701.5332\n",
      "Epoch 28/300\n",
      "1168/1168 [==============================] - 0s 143us/sample - loss: 162299.2241 - val_loss: 156750.3217\n",
      "Epoch 29/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 160061.2395 - val_loss: 154679.2532\n",
      "Epoch 30/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 157684.7826 - val_loss: 152461.6877\n",
      "Epoch 31/300\n",
      "1168/1168 [==============================] - 0s 122us/sample - loss: 155147.8502 - val_loss: 150109.8831\n",
      "Epoch 32/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 152468.8506 - val_loss: 147622.2389\n",
      "Epoch 33/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 149618.9662 - val_loss: 144989.9580\n",
      "Epoch 34/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 146609.5538 - val_loss: 142218.0216\n",
      "Epoch 35/300\n",
      "1168/1168 [==============================] - 0s 137us/sample - loss: 143459.2358 - val_loss: 139286.0355\n",
      "Epoch 36/300\n",
      "1168/1168 [==============================] - 0s 133us/sample - loss: 140134.0775 - val_loss: 136235.7173\n",
      "Epoch 37/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 136658.7562 - val_loss: 133037.2650\n",
      "Epoch 38/300\n",
      "1168/1168 [==============================] - 0s 122us/sample - loss: 133034.0662 - val_loss: 129699.5121\n",
      "Epoch 39/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 129264.7078 - val_loss: 126206.0442\n",
      "Epoch 40/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 125327.6886 - val_loss: 122555.9741\n",
      "Epoch 41/300\n",
      "1168/1168 [==============================] - 0s 123us/sample - loss: 121223.4568 - val_loss: 118801.6617\n",
      "Epoch 42/300\n",
      "1168/1168 [==============================] - 0s 121us/sample - loss: 116953.0576 - val_loss: 114893.9003\n",
      "Epoch 43/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 112549.1210 - val_loss: 110839.4604\n",
      "Epoch 44/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 108015.0825 - val_loss: 106662.4020\n",
      "Epoch 45/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 103360.9351 - val_loss: 102391.4048\n",
      "Epoch 46/300\n",
      "1168/1168 [==============================] - 0s 138us/sample - loss: 98564.8643 - val_loss: 98011.4113\n",
      "Epoch 47/300\n",
      "1168/1168 [==============================] - 0s 143us/sample - loss: 93681.7987 - val_loss: 93615.5165\n",
      "Epoch 48/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 88768.2403 - val_loss: 89163.8119\n",
      "Epoch 49/300\n",
      "1168/1168 [==============================] - 0s 121us/sample - loss: 83868.7914 - val_loss: 84707.0939\n",
      "Epoch 50/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 78983.9298 - val_loss: 80234.7610\n",
      "Epoch 51/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 74137.8549 - val_loss: 75958.8753\n",
      "Epoch 52/300\n",
      "1168/1168 [==============================] - 0s 155us/sample - loss: 69387.1281 - val_loss: 71808.9893\n",
      "Epoch 53/300\n",
      "1168/1168 [==============================] - 0s 136us/sample - loss: 64775.0109 - val_loss: 67648.6890\n",
      "Epoch 54/300\n",
      "1168/1168 [==============================] - 0s 131us/sample - loss: 60439.2485 - val_loss: 63707.5455\n",
      "Epoch 55/300\n",
      "1168/1168 [==============================] - 0s 131us/sample - loss: 56502.8595 - val_loss: 60013.9000\n",
      "Epoch 56/300\n",
      "1168/1168 [==============================] - 0s 121us/sample - loss: 52956.3946 - val_loss: 56665.5023\n",
      "Epoch 57/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 49924.5255 - val_loss: 53733.1805\n",
      "Epoch 58/300\n",
      "1168/1168 [==============================] - 0s 122us/sample - loss: 47272.0751 - val_loss: 51249.2984\n",
      "Epoch 59/300\n",
      "1168/1168 [==============================] - 0s 122us/sample - loss: 44970.2805 - val_loss: 48975.8854\n",
      "Epoch 60/300\n",
      "1168/1168 [==============================] - 0s 125us/sample - loss: 42902.5144 - val_loss: 46991.5652\n",
      "Epoch 61/300\n",
      "1168/1168 [==============================] - 0s 103us/sample - loss: 41187.2704 - val_loss: 45216.5491\n",
      "Epoch 62/300\n",
      "1168/1168 [==============================] - 0s 108us/sample - loss: 39754.8863 - val_loss: 43628.8977\n",
      "Epoch 63/300\n",
      "1168/1168 [==============================] - 0s 126us/sample - loss: 38481.0687 - val_loss: 42268.5948\n",
      "Epoch 64/300\n",
      "1168/1168 [==============================] - 0s 122us/sample - loss: 37307.0423 - val_loss: 41110.4229\n",
      "Epoch 65/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 36259.7843 - val_loss: 39954.7204\n",
      "Epoch 66/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 35265.1035 - val_loss: 38918.1479\n",
      "Epoch 67/300\n",
      "1168/1168 [==============================] - 0s 121us/sample - loss: 34395.9158 - val_loss: 38010.1313\n",
      "Epoch 68/300\n",
      "1168/1168 [==============================] - 0s 133us/sample - loss: 33604.5910 - val_loss: 37150.1469\n",
      "Epoch 69/300\n",
      "1168/1168 [==============================] - 0s 137us/sample - loss: 32860.6733 - val_loss: 36407.1879\n",
      "Epoch 70/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 143us/sample - loss: 32198.4423 - val_loss: 35692.2859\n",
      "Epoch 71/300\n",
      "1168/1168 [==============================] - 0s 126us/sample - loss: 31572.5427 - val_loss: 35041.8146\n",
      "Epoch 72/300\n",
      "1168/1168 [==============================] - 0s 126us/sample - loss: 30988.1066 - val_loss: 34420.1942\n",
      "Epoch 73/300\n",
      "1168/1168 [==============================] - 0s 161us/sample - loss: 30453.9391 - val_loss: 33873.4838\n",
      "Epoch 74/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 29959.6313 - val_loss: 33380.4099\n",
      "Epoch 75/300\n",
      "1168/1168 [==============================] - 0s 121us/sample - loss: 29488.9785 - val_loss: 32888.6268\n",
      "Epoch 76/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 29044.3983 - val_loss: 32442.9533\n",
      "Epoch 77/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 28624.2076 - val_loss: 32018.8920\n",
      "Epoch 78/300\n",
      "1168/1168 [==============================] - 0s 110us/sample - loss: 28231.6231 - val_loss: 31613.2945\n",
      "Epoch 79/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 27857.5196 - val_loss: 31267.2375\n",
      "Epoch 80/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 27520.6869 - val_loss: 30910.9423\n",
      "Epoch 81/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 27185.3142 - val_loss: 30573.5559\n",
      "Epoch 82/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 26882.9968 - val_loss: 30284.5674\n",
      "Epoch 83/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 26598.3967 - val_loss: 30004.2476\n",
      "Epoch 84/300\n",
      "1168/1168 [==============================] - 0s 121us/sample - loss: 26315.4266 - val_loss: 29746.8651\n",
      "Epoch 85/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 26053.3381 - val_loss: 29457.6924\n",
      "Epoch 86/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 25801.2274 - val_loss: 29238.0415\n",
      "Epoch 87/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 25573.9602 - val_loss: 29018.3093\n",
      "Epoch 88/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 25356.1196 - val_loss: 28787.6390\n",
      "Epoch 89/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 25146.0039 - val_loss: 28555.4148\n",
      "Epoch 90/300\n",
      "1168/1168 [==============================] - 0s 110us/sample - loss: 24943.8984 - val_loss: 28353.4312\n",
      "Epoch 91/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 24750.9203 - val_loss: 28143.2627\n",
      "Epoch 92/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 24569.2089 - val_loss: 27999.5031\n",
      "Epoch 93/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 24395.2789 - val_loss: 27794.7737\n",
      "Epoch 94/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 24222.0318 - val_loss: 27642.6988\n",
      "Epoch 95/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 24064.7046 - val_loss: 27479.0743\n",
      "Epoch 96/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 23905.3030 - val_loss: 27299.2441\n",
      "Epoch 97/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 23754.2836 - val_loss: 27168.3808\n",
      "Epoch 98/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 23595.6552 - val_loss: 27032.9340\n",
      "Epoch 99/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 23456.6156 - val_loss: 26923.8461\n",
      "Epoch 100/300\n",
      "1168/1168 [==============================] - 0s 135us/sample - loss: 23320.2470 - val_loss: 26798.9002\n",
      "Epoch 101/300\n",
      "1168/1168 [==============================] - 0s 126us/sample - loss: 23184.8118 - val_loss: 26698.4666\n",
      "Epoch 102/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 23060.1270 - val_loss: 26590.1431\n",
      "Epoch 103/300\n",
      "1168/1168 [==============================] - 0s 113us/sample - loss: 22942.4229 - val_loss: 26512.1017\n",
      "Epoch 104/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 22824.5880 - val_loss: 26421.8763\n",
      "Epoch 105/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 22706.1137 - val_loss: 26335.9316\n",
      "Epoch 106/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 22596.1382 - val_loss: 26259.6191\n",
      "Epoch 107/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 22484.6088 - val_loss: 26174.6439\n",
      "Epoch 108/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 22372.0608 - val_loss: 26108.5452\n",
      "Epoch 109/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 22263.5017 - val_loss: 26034.1744\n",
      "Epoch 110/300\n",
      "1168/1168 [==============================] - 0s 121us/sample - loss: 22155.8515 - val_loss: 25948.4385\n",
      "Epoch 111/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 22046.9360 - val_loss: 25895.1108\n",
      "Epoch 112/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 21945.6562 - val_loss: 25820.0696\n",
      "Epoch 113/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 21851.0895 - val_loss: 25740.8755\n",
      "Epoch 114/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 21755.6385 - val_loss: 25664.6685\n",
      "Epoch 115/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 21656.6624 - val_loss: 25621.2572\n",
      "Epoch 116/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 21567.4098 - val_loss: 25556.3475\n",
      "Epoch 117/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 21485.3531 - val_loss: 25481.5095\n",
      "Epoch 118/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 21395.4185 - val_loss: 25428.8086\n",
      "Epoch 119/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 21314.1569 - val_loss: 25355.5183\n",
      "Epoch 120/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 21228.0222 - val_loss: 25306.7137\n",
      "Epoch 121/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 21151.3924 - val_loss: 25248.7281\n",
      "Epoch 122/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 21076.1322 - val_loss: 25180.5659\n",
      "Epoch 123/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 20997.4071 - val_loss: 25123.0984\n",
      "Epoch 124/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 20926.1146 - val_loss: 25080.9273\n",
      "Epoch 125/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 20858.6920 - val_loss: 25031.6402\n",
      "Epoch 126/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 20777.1234 - val_loss: 24953.0608\n",
      "Epoch 127/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 20698.3655 - val_loss: 24909.7891\n",
      "Epoch 128/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 20637.8854 - val_loss: 24840.0650\n",
      "Epoch 129/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 20558.0515 - val_loss: 24808.4865\n",
      "Epoch 130/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 20497.0638 - val_loss: 24732.8226\n",
      "Epoch 131/300\n",
      "1168/1168 [==============================] - 0s 121us/sample - loss: 20421.0393 - val_loss: 24686.2030\n",
      "Epoch 132/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 20358.5503 - val_loss: 24643.2610\n",
      "Epoch 133/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 20290.0948 - val_loss: 24611.5554\n",
      "Epoch 134/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 20220.3699 - val_loss: 24538.6758\n",
      "Epoch 135/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 20155.7402 - val_loss: 24508.1622\n",
      "Epoch 136/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 20087.9671 - val_loss: 24469.7123\n",
      "Epoch 137/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 20030.6483 - val_loss: 24412.7643\n",
      "Epoch 138/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 19968.7585 - val_loss: 24350.3693\n",
      "Epoch 139/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 19912.2270 - val_loss: 24318.1154\n",
      "Epoch 140/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 118us/sample - loss: 19850.5398 - val_loss: 24274.4060\n",
      "Epoch 141/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 19793.7333 - val_loss: 24202.6819\n",
      "Epoch 142/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 19725.9098 - val_loss: 24170.0924\n",
      "Epoch 143/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 19669.5028 - val_loss: 24117.1799\n",
      "Epoch 144/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 19619.8104 - val_loss: 24068.7299\n",
      "Epoch 145/300\n",
      "1168/1168 [==============================] - 0s 111us/sample - loss: 19553.2520 - val_loss: 24037.2542\n",
      "Epoch 146/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 19500.2613 - val_loss: 23990.7579\n",
      "Epoch 147/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 19444.5329 - val_loss: 23937.8825\n",
      "Epoch 148/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 19386.0414 - val_loss: 23886.4742\n",
      "Epoch 149/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 19339.9252 - val_loss: 23827.4672\n",
      "Epoch 150/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 19280.4321 - val_loss: 23801.8379\n",
      "Epoch 151/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 19223.9603 - val_loss: 23763.5746\n",
      "Epoch 152/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 19178.8150 - val_loss: 23722.3801\n",
      "Epoch 153/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 19123.6642 - val_loss: 23685.6701\n",
      "Epoch 154/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 19082.6387 - val_loss: 23635.5841\n",
      "Epoch 155/300\n",
      "1168/1168 [==============================] - 0s 113us/sample - loss: 19023.0427 - val_loss: 23611.8696\n",
      "Epoch 156/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 18979.0498 - val_loss: 23563.5958\n",
      "Epoch 157/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 18935.8625 - val_loss: 23525.8934\n",
      "Epoch 158/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 18886.6935 - val_loss: 23476.2730\n",
      "Epoch 159/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 18842.5305 - val_loss: 23432.0082\n",
      "Epoch 160/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 18803.5870 - val_loss: 23416.4350\n",
      "Epoch 161/300\n",
      "1168/1168 [==============================] - 0s 125us/sample - loss: 18753.9616 - val_loss: 23357.6740\n",
      "Epoch 162/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 18722.8526 - val_loss: 23329.8498\n",
      "Epoch 163/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 18663.1980 - val_loss: 23299.9147\n",
      "Epoch 164/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 18624.3235 - val_loss: 23264.6283\n",
      "Epoch 165/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 18568.9972 - val_loss: 23225.7537\n",
      "Epoch 166/300\n",
      "1168/1168 [==============================] - 0s 122us/sample - loss: 18528.2780 - val_loss: 23190.4327\n",
      "Epoch 167/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 18496.8323 - val_loss: 23149.9115\n",
      "Epoch 168/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 18448.9601 - val_loss: 23132.9083\n",
      "Epoch 169/300\n",
      "1168/1168 [==============================] - 0s 113us/sample - loss: 18406.4682 - val_loss: 23097.9863\n",
      "Epoch 170/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 18359.2829 - val_loss: 23056.5642\n",
      "Epoch 171/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 18321.1954 - val_loss: 23016.1571\n",
      "Epoch 172/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 18283.8902 - val_loss: 23003.2597\n",
      "Epoch 173/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 18260.5769 - val_loss: 22969.7090\n",
      "Epoch 174/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 18198.3937 - val_loss: 22927.4387\n",
      "Epoch 175/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 18156.8073 - val_loss: 22897.5614\n",
      "Epoch 176/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 18115.6342 - val_loss: 22868.3705\n",
      "Epoch 177/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 18075.1994 - val_loss: 22843.3497\n",
      "Epoch 178/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 18036.1991 - val_loss: 22812.1279\n",
      "Epoch 179/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 18006.9812 - val_loss: 22778.7869\n",
      "Epoch 180/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 17961.1604 - val_loss: 22755.5382\n",
      "Epoch 181/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 17926.7705 - val_loss: 22712.2898\n",
      "Epoch 182/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 17882.5707 - val_loss: 22705.3789\n",
      "Epoch 183/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 17851.5476 - val_loss: 22668.6351\n",
      "Epoch 184/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 17820.6123 - val_loss: 22634.9256\n",
      "Epoch 185/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 17780.2754 - val_loss: 22602.4143\n",
      "Epoch 186/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 17753.3531 - val_loss: 22583.3396\n",
      "Epoch 187/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 17714.6847 - val_loss: 22537.4524\n",
      "Epoch 188/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 17677.7760 - val_loss: 22508.0468\n",
      "Epoch 189/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 17638.0283 - val_loss: 22494.5941\n",
      "Epoch 190/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 17609.7315 - val_loss: 22464.5893\n",
      "Epoch 191/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 17573.8956 - val_loss: 22433.9786\n",
      "Epoch 192/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 17539.3608 - val_loss: 22413.5666\n",
      "Epoch 193/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 17509.7893 - val_loss: 22378.4712\n",
      "Epoch 194/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 17478.5323 - val_loss: 22358.8913\n",
      "Epoch 195/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 17444.3206 - val_loss: 22307.4215\n",
      "Epoch 196/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 17415.0594 - val_loss: 22290.2505\n",
      "Epoch 197/300\n",
      "1168/1168 [==============================] - 0s 110us/sample - loss: 17373.2456 - val_loss: 22260.4092\n",
      "Epoch 198/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 17347.0055 - val_loss: 22248.6821\n",
      "Epoch 199/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 17312.3971 - val_loss: 22210.1664\n",
      "Epoch 200/300\n",
      "1168/1168 [==============================] - 0s 100us/sample - loss: 17275.4187 - val_loss: 22210.2873\n",
      "Epoch 201/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 17248.4485 - val_loss: 22163.2850\n",
      "Epoch 202/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 17217.7348 - val_loss: 22152.3264\n",
      "Epoch 203/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 17181.4195 - val_loss: 22111.5375\n",
      "Epoch 204/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 17162.5209 - val_loss: 22085.7258\n",
      "Epoch 205/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 17129.0720 - val_loss: 22046.9500\n",
      "Epoch 206/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 17099.3366 - val_loss: 22034.2052\n",
      "Epoch 207/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 17073.6926 - val_loss: 22013.3736\n",
      "Epoch 208/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 17037.8895 - val_loss: 21999.7954\n",
      "Epoch 209/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 17016.0626 - val_loss: 21967.7301\n",
      "Epoch 210/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 120us/sample - loss: 16973.1864 - val_loss: 21942.2799\n",
      "Epoch 211/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 16951.8579 - val_loss: 21914.0047\n",
      "Epoch 212/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 16930.3551 - val_loss: 21896.6235\n",
      "Epoch 213/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 16884.7882 - val_loss: 21874.0920\n",
      "Epoch 214/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 16856.5467 - val_loss: 21855.2965\n",
      "Epoch 215/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 16832.2293 - val_loss: 21824.3917\n",
      "Epoch 216/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 16809.3106 - val_loss: 21813.4642\n",
      "Epoch 217/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 16775.5222 - val_loss: 21787.5889\n",
      "Epoch 218/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 16744.2089 - val_loss: 21755.2445\n",
      "Epoch 219/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 16722.8535 - val_loss: 21736.8147\n",
      "Epoch 220/300\n",
      "1168/1168 [==============================] - 0s 111us/sample - loss: 16700.9477 - val_loss: 21721.0143\n",
      "Epoch 221/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 16665.3685 - val_loss: 21693.3600\n",
      "Epoch 222/300\n",
      "1168/1168 [==============================] - 0s 112us/sample - loss: 16639.1196 - val_loss: 21670.2225\n",
      "Epoch 223/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 16612.3801 - val_loss: 21656.3927\n",
      "Epoch 224/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 16586.9199 - val_loss: 21627.8035\n",
      "Epoch 225/300\n",
      "1168/1168 [==============================] - 0s 102us/sample - loss: 16564.4276 - val_loss: 21628.8380\n",
      "Epoch 226/300\n",
      "1168/1168 [==============================] - 0s 113us/sample - loss: 16534.9423 - val_loss: 21560.5017\n",
      "Epoch 227/300\n",
      "1168/1168 [==============================] - 0s 105us/sample - loss: 16511.1870 - val_loss: 21588.4050\n",
      "Epoch 228/300\n",
      "1168/1168 [==============================] - 0s 126us/sample - loss: 16476.6398 - val_loss: 21555.6633\n",
      "Epoch 229/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 16461.4180 - val_loss: 21530.0801\n",
      "Epoch 230/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 16432.2846 - val_loss: 21489.4173\n",
      "Epoch 231/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 16404.1832 - val_loss: 21479.1863\n",
      "Epoch 232/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 16374.7943 - val_loss: 21454.6818\n",
      "Epoch 233/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 16351.8755 - val_loss: 21418.0359\n",
      "Epoch 234/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 16321.2380 - val_loss: 21410.3203\n",
      "Epoch 235/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 16305.0497 - val_loss: 21389.8444\n",
      "Epoch 236/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 16268.7241 - val_loss: 21341.8381\n",
      "Epoch 237/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 16261.5721 - val_loss: 21335.1154\n",
      "Epoch 238/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 16224.5293 - val_loss: 21307.1247\n",
      "Epoch 239/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 16194.0784 - val_loss: 21294.2888\n",
      "Epoch 240/300\n",
      "1168/1168 [==============================] - 0s 130us/sample - loss: 16166.5783 - val_loss: 21248.9794\n",
      "Epoch 241/300\n",
      "1168/1168 [==============================] - 0s 104us/sample - loss: 16142.9009 - val_loss: 21252.1842\n",
      "Epoch 242/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 16117.2985 - val_loss: 21216.2980\n",
      "Epoch 243/300\n",
      "1168/1168 [==============================] - 0s 107us/sample - loss: 16106.3512 - val_loss: 21250.5702\n",
      "Epoch 244/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 16102.8517 - val_loss: 21214.3255\n",
      "Epoch 245/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 16048.1841 - val_loss: 21173.9323\n",
      "Epoch 246/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 16025.5580 - val_loss: 21146.0954\n",
      "Epoch 247/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 16002.3202 - val_loss: 21133.2702\n",
      "Epoch 248/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 15980.6501 - val_loss: 21122.0020\n",
      "Epoch 249/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 15955.8389 - val_loss: 21087.8252\n",
      "Epoch 250/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 15924.9822 - val_loss: 21067.7996\n",
      "Epoch 251/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 15910.2047 - val_loss: 21055.7301\n",
      "Epoch 252/300\n",
      "1168/1168 [==============================] - 0s 103us/sample - loss: 15896.6266 - val_loss: 21069.9229\n",
      "Epoch 253/300\n",
      "1168/1168 [==============================] - 0s 113us/sample - loss: 15877.9975 - val_loss: 21011.7600\n",
      "Epoch 254/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 15842.0666 - val_loss: 20987.3265\n",
      "Epoch 255/300\n",
      "1168/1168 [==============================] - 0s 126us/sample - loss: 15816.4472 - val_loss: 20981.5209\n",
      "Epoch 256/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 15787.1932 - val_loss: 20960.6488\n",
      "Epoch 257/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 15767.3146 - val_loss: 20944.8508\n",
      "Epoch 258/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 15736.3437 - val_loss: 20917.1636\n",
      "Epoch 259/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 15715.3512 - val_loss: 20907.0687\n",
      "Epoch 260/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 15698.0258 - val_loss: 20889.2076\n",
      "Epoch 261/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 15684.0147 - val_loss: 20864.7046\n",
      "Epoch 262/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 15658.5203 - val_loss: 20829.9430\n",
      "Epoch 263/300\n",
      "1168/1168 [==============================] - 0s 124us/sample - loss: 15628.7852 - val_loss: 20828.6876\n",
      "Epoch 264/300\n",
      "1168/1168 [==============================] - 0s 121us/sample - loss: 15601.2060 - val_loss: 20813.8188\n",
      "Epoch 265/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 15589.3114 - val_loss: 20786.3263\n",
      "Epoch 266/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 15559.2032 - val_loss: 20767.7628\n",
      "Epoch 267/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 15539.2064 - val_loss: 20764.2124\n",
      "Epoch 268/300\n",
      "1168/1168 [==============================] - 0s 119us/sample - loss: 15528.2199 - val_loss: 20725.8423\n",
      "Epoch 269/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 15502.8501 - val_loss: 20714.2614\n",
      "Epoch 270/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 15478.8177 - val_loss: 20713.5948\n",
      "Epoch 271/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 15454.5668 - val_loss: 20670.3427\n",
      "Epoch 272/300\n",
      "1168/1168 [==============================] - 0s 99us/sample - loss: 15428.2812 - val_loss: 20694.8405\n",
      "Epoch 273/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 15418.0815 - val_loss: 20661.0274\n",
      "Epoch 274/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 15386.7924 - val_loss: 20628.9314\n",
      "Epoch 275/300\n",
      "1168/1168 [==============================] - 0s 100us/sample - loss: 15363.9253 - val_loss: 20648.0149\n",
      "Epoch 276/300\n",
      "1168/1168 [==============================] - 0s 102us/sample - loss: 15350.9634 - val_loss: 20630.5854\n",
      "Epoch 277/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 15327.3227 - val_loss: 20588.2310\n",
      "Epoch 278/300\n",
      "1168/1168 [==============================] - 0s 105us/sample - loss: 15309.3128 - val_loss: 20603.6325\n",
      "Epoch 279/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 15286.8213 - val_loss: 20581.7979\n",
      "Epoch 280/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168/1168 [==============================] - 0s 120us/sample - loss: 15272.4469 - val_loss: 20575.6195\n",
      "Epoch 281/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 15251.7795 - val_loss: 20550.2591\n",
      "Epoch 282/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 15237.8746 - val_loss: 20544.3879\n",
      "Epoch 283/300\n",
      "1168/1168 [==============================] - 0s 113us/sample - loss: 15214.7854 - val_loss: 20541.2527\n",
      "Epoch 284/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 15190.6476 - val_loss: 20533.3993\n",
      "Epoch 285/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 15188.9263 - val_loss: 20522.3724\n",
      "Epoch 286/300\n",
      "1168/1168 [==============================] - 0s 115us/sample - loss: 15159.8421 - val_loss: 20509.8321\n",
      "Epoch 287/300\n",
      "1168/1168 [==============================] - 0s 113us/sample - loss: 15132.3704 - val_loss: 20504.2248\n",
      "Epoch 288/300\n",
      "1168/1168 [==============================] - 0s 102us/sample - loss: 15114.5467 - val_loss: 20505.6905\n",
      "Epoch 289/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 15104.9903 - val_loss: 20494.6752\n",
      "Epoch 290/300\n",
      "1168/1168 [==============================] - 0s 116us/sample - loss: 15093.5876 - val_loss: 20449.7966\n",
      "Epoch 291/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 15067.0362 - val_loss: 20446.9221\n",
      "Epoch 292/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 15053.8175 - val_loss: 20432.5062\n",
      "Epoch 293/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 15032.1690 - val_loss: 20430.3551\n",
      "Epoch 294/300\n",
      "1168/1168 [==============================] - 0s 114us/sample - loss: 15007.0562 - val_loss: 20429.2782\n",
      "Epoch 295/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 14996.0895 - val_loss: 20404.4088\n",
      "Epoch 296/300\n",
      "1168/1168 [==============================] - 0s 118us/sample - loss: 14972.2357 - val_loss: 20380.9108\n",
      "Epoch 297/300\n",
      "1168/1168 [==============================] - 0s 120us/sample - loss: 14960.6849 - val_loss: 20368.1921\n",
      "Epoch 298/300\n",
      "1168/1168 [==============================] - 0s 104us/sample - loss: 14935.2670 - val_loss: 20401.1074\n",
      "Epoch 299/300\n",
      "1168/1168 [==============================] - 0s 102us/sample - loss: 14920.3378 - val_loss: 20369.0916\n",
      "Epoch 300/300\n",
      "1168/1168 [==============================] - 0s 117us/sample - loss: 14902.4636 - val_loss: 20353.9578\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32,\n",
    "                    epochs=epoch, callbacks=[lr_scheduler_pfm, checkpoint_callback, early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:17:02.826972Z",
     "start_time": "2020-05-29T10:17:02.672343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Val'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T10:15:15.196519Z",
     "start_time": "2020-05-29T10:15:08.565Z"
    }
   },
   "outputs": [],
   "source": [
    "##  NN is not suitable for regression task, hard for hyperparameter tuning and explanation\n",
    "##  MAE > 20000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
