{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dropout,Dense,Embedding,BatchNormalization,Dropout,GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "pd_all = pd.read_csv(path + 'ChnSentiCorp_htl_all.csv')\n",
    "\n",
    "pd_positive = pd_all[pd_all.label==1]\n",
    "pd_negative = pd_all[pd_all.label==0]\n",
    "\n",
    "def get_balance_corpus(corpus_size, corpus_pos, corpus_neg):\n",
    "    sample_size = corpus_size // 2\n",
    "    pd_corpus_balance = pd.concat([corpus_pos.sample(sample_size, replace=corpus_pos.shape[0]<sample_size), \\\n",
    "                                   corpus_neg.sample(sample_size, replace=corpus_neg.shape[0]<sample_size)])\n",
    "    \n",
    "    print('评论数目（总体）：%d' % pd_corpus_balance.shape[0])\n",
    "    print('评论数目（正向）：%d' % pd_corpus_balance[pd_corpus_balance.label==1].shape[0])\n",
    "    print('评论数目（负向）：%d' % pd_corpus_balance[pd_corpus_balance.label==0].shape[0])    \n",
    "    \n",
    "    return pd_corpus_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评论数目（总体）：2000\n",
      "评论数目（正向）：1000\n",
      "评论数目（负向）：1000\n"
     ]
    }
   ],
   "source": [
    "import hanlp\n",
    "tokenizer = hanlp.load('LARGE_ALBERT_BASE')\n",
    "\n",
    "ChnSentiCorp_htl_ba_2000 = get_balance_corpus(2000, pd_positive, pd_negative)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ChnSentiCorp_htl_ba_2000.review.tolist()\n",
    "import re\n",
    "\n",
    "def find_chn(list_of_string):  #提取汉字\n",
    "    list_s = []\n",
    "    pattern = re.compile(r'[^\\u4e00-\\u9fa5]')\n",
    "    for s in list_of_string:\n",
    "        s = re.sub(pattern,'',s)\n",
    "        list_s.append(s)\n",
    "    return list_s\n",
    "        \n",
    "X_chn = find_chn(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_str(list_of_string,length):   # 切割字符串，保留最后100个汉字\n",
    "    X_cut = []\n",
    "    for i in list_of_string:\n",
    "        X_cut.append(i[-1*length:])\n",
    "    return X_cut\n",
    "\n",
    "X_cut = trunc_str(X_chn,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_token = tokenizer(X_cut)  # 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['于',\n",
       " '给到',\n",
       " '我们',\n",
       " '的',\n",
       " '房间',\n",
       " '与',\n",
       " '我们',\n",
       " '的',\n",
       " '要求',\n",
       " '有',\n",
       " '出入',\n",
       " '酒店',\n",
       " '人员',\n",
       " '立即',\n",
       " '想',\n",
       " '办法',\n",
       " '帮',\n",
       " '我们',\n",
       " '解决',\n",
       " '听说',\n",
       " '是',\n",
       " '他们',\n",
       " '的',\n",
       " '财务',\n",
       " '经理',\n",
       " '把',\n",
       " '房间',\n",
       " '让给',\n",
       " '了',\n",
       " '我们',\n",
       " '让',\n",
       " '我们',\n",
       " '很',\n",
       " '感动',\n",
       " '房间',\n",
       " '的',\n",
       " '价钱',\n",
       " '贵了点',\n",
       " '但',\n",
       " '物有所值',\n",
       " '下次',\n",
       " '去',\n",
       " '九寨沟',\n",
       " '还',\n",
       " '住',\n",
       " '喜来',\n",
       " '登',\n",
       " '这次',\n",
       " '汶川',\n",
       " '地震',\n",
       " '应该',\n",
       " '没有',\n",
       " '影响',\n",
       " '到',\n",
       " '他们',\n",
       " '吧',\n",
       " '祝',\n",
       " '一切',\n",
       " '平安']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_token[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=X_token, size = 100, window = 5, min_count=1, workers = 4)\n",
    "model.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.83350935e-04, -8.27597231e-02,  3.36558849e-01, -3.60424519e-02,\n",
       "       -1.86550587e-01, -2.68017985e-02, -2.21636370e-01, -1.11095332e-01,\n",
       "       -8.84630382e-02,  1.10094801e-01, -1.97244599e-01,  1.56114876e-01,\n",
       "       -8.80174264e-02,  4.47545387e-02, -1.06314436e-01, -2.27199107e-01,\n",
       "        5.25917597e-02, -1.73749235e-02, -2.33041599e-01,  1.61826819e-01,\n",
       "        2.06463665e-01,  1.07508063e-01, -2.33329311e-01,  8.47866833e-02,\n",
       "        1.36503294e-01, -3.50240548e-03, -8.46235976e-02,  1.85038134e-01,\n",
       "        8.97972435e-02, -5.57922833e-02,  2.38069490e-01, -1.11047946e-01,\n",
       "       -3.02047879e-01,  1.59190029e-01, -6.55211359e-02,  8.01820755e-02,\n",
       "        1.00730203e-01,  1.68091476e-01, -5.44425473e-02, -8.55500326e-02,\n",
       "       -2.04417184e-01,  8.49214643e-02, -1.00701056e-01, -9.04012248e-02,\n",
       "       -3.79488128e-03,  1.11045867e-01, -9.65351355e-04, -7.00161234e-02,\n",
       "       -1.31335765e-01, -4.58520204e-02, -9.54950675e-02,  4.37584892e-02,\n",
       "       -7.24981129e-02,  8.57368186e-02, -2.34557688e-02, -7.71881193e-02,\n",
       "        1.80479005e-01, -4.40519378e-02,  6.24643452e-03, -1.71948463e-01,\n",
       "        1.92312058e-02,  6.27728999e-02, -2.67452091e-01,  1.27441406e-01,\n",
       "        8.79007503e-02,  1.48849323e-01, -9.82642248e-02, -8.36981460e-02,\n",
       "       -8.24870989e-02, -9.08308402e-02,  9.17887539e-02,  1.45162806e-01,\n",
       "        1.94069430e-01, -2.72730798e-01, -8.58935621e-03, -8.36071074e-02,\n",
       "       -7.77626559e-02, -6.03134967e-02,  2.82593846e-01,  3.41641530e-02,\n",
       "       -1.78075787e-02,  1.56431332e-01, -8.26133043e-02, -9.53829214e-02,\n",
       "       -3.61456419e-03,  2.31214181e-01, -9.20087472e-02,  1.84585914e-01,\n",
       "       -3.76888961e-01, -1.94799602e-02, -2.58120522e-02,  5.55270351e-03,\n",
       "       -8.79871566e-03, -2.51863509e-01,  2.60712076e-02,  1.02073953e-01,\n",
       "        1.91281155e-01, -1.91291068e-02,  1.29357547e-01, -2.33769156e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看单词的词向量\n",
    "vector = model.wv['缺点']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "好用 0.930890679359436\n",
      "晚饭 0.930504560470581\n",
      "一会 0.9302356243133545\n",
      "开灯 0.9301743507385254\n",
      "矿业 0.9299736022949219\n",
      "妹子 0.9298959970474243\n",
      "表达 0.9295830726623535\n",
      "到底 0.9292734861373901\n"
     ]
    }
   ],
   "source": [
    "# 给定单词，找出含义最接近的词\n",
    "request_count = 5\n",
    "for key in model.wv.similar_by_word('抽烟',topn=10):\n",
    "        if len(key[0])==2:\n",
    "            request_count -= -1\n",
    "            print(key[0],key[1])\n",
    "            if request_count ==0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99982166\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.similarity('豪华', '商务'))  #余弦相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7920965\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.similarity('平安', '听说'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
