{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568438 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('AmazonReviews.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df.Text.to_list()\n",
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i',\n",
       "  'have',\n",
       "  'bought',\n",
       "  'several',\n",
       "  'of',\n",
       "  'the',\n",
       "  'vitality',\n",
       "  'canned',\n",
       "  'dog',\n",
       "  'food',\n",
       "  'products',\n",
       "  'and',\n",
       "  'have',\n",
       "  'found',\n",
       "  'them',\n",
       "  'all',\n",
       "  'to',\n",
       "  'be',\n",
       "  'of',\n",
       "  'good',\n",
       "  'quality',\n",
       "  'the',\n",
       "  'product',\n",
       "  'looks',\n",
       "  'more',\n",
       "  'like',\n",
       "  'a',\n",
       "  'stew',\n",
       "  'than',\n",
       "  'a',\n",
       "  'processed',\n",
       "  'meat',\n",
       "  'and',\n",
       "  'it',\n",
       "  'smells',\n",
       "  'better',\n",
       "  'my',\n",
       "  'labrador',\n",
       "  'is',\n",
       "  'finicky',\n",
       "  'and',\n",
       "  'she',\n",
       "  'appreciates',\n",
       "  'this',\n",
       "  'product',\n",
       "  'better',\n",
       "  'than',\n",
       "  'most'],\n",
       " ['product',\n",
       "  'arrived',\n",
       "  'labeled',\n",
       "  'as',\n",
       "  'jumbo',\n",
       "  'salted',\n",
       "  'peanutsthe',\n",
       "  'peanuts',\n",
       "  'were',\n",
       "  'actually',\n",
       "  'small',\n",
       "  'sized',\n",
       "  'unsalted',\n",
       "  'not',\n",
       "  'sure',\n",
       "  'if',\n",
       "  'this',\n",
       "  'was',\n",
       "  'an',\n",
       "  'error',\n",
       "  'or',\n",
       "  'if',\n",
       "  'the',\n",
       "  'vendor',\n",
       "  'intended',\n",
       "  'to',\n",
       "  'represent',\n",
       "  'the',\n",
       "  'product',\n",
       "  'as',\n",
       "  'jumbo'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'confection',\n",
       "  'that',\n",
       "  'has',\n",
       "  'been',\n",
       "  'around',\n",
       "  'a',\n",
       "  'few',\n",
       "  'centuries',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'light',\n",
       "  'pillowy',\n",
       "  'citrus',\n",
       "  'gelatin',\n",
       "  'with',\n",
       "  'nuts',\n",
       "  'in',\n",
       "  'this',\n",
       "  'case',\n",
       "  'filberts',\n",
       "  'and',\n",
       "  'it',\n",
       "  'is',\n",
       "  'cut',\n",
       "  'into',\n",
       "  'tiny',\n",
       "  'squares',\n",
       "  'and',\n",
       "  'then',\n",
       "  'liberally',\n",
       "  'coated',\n",
       "  'with',\n",
       "  'powdered',\n",
       "  'sugar',\n",
       "  'and',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'tiny',\n",
       "  'mouthful',\n",
       "  'of',\n",
       "  'heaven',\n",
       "  'not',\n",
       "  'too',\n",
       "  'chewy',\n",
       "  'and',\n",
       "  'very',\n",
       "  'flavorful',\n",
       "  'i',\n",
       "  'highly',\n",
       "  'recommend',\n",
       "  'this',\n",
       "  'yummy',\n",
       "  'treat',\n",
       "  'if',\n",
       "  'you',\n",
       "  'are',\n",
       "  'familiar',\n",
       "  'with',\n",
       "  'the',\n",
       "  'story',\n",
       "  'of',\n",
       "  'cs',\n",
       "  'lewis',\n",
       "  'the',\n",
       "  'lion',\n",
       "  'the',\n",
       "  'witch',\n",
       "  'and',\n",
       "  'the',\n",
       "  'wardrobe',\n",
       "  'this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'treat',\n",
       "  'that',\n",
       "  'seduces',\n",
       "  'edmund',\n",
       "  'into',\n",
       "  'selling',\n",
       "  'out',\n",
       "  'his',\n",
       "  'brother',\n",
       "  'and',\n",
       "  'sisters',\n",
       "  'to',\n",
       "  'the',\n",
       "  'witch'],\n",
       " ['if',\n",
       "  'you',\n",
       "  'are',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'the',\n",
       "  'secret',\n",
       "  'ingredient',\n",
       "  'in',\n",
       "  'robitussin',\n",
       "  'i',\n",
       "  'believe',\n",
       "  'i',\n",
       "  'have',\n",
       "  'found',\n",
       "  'it',\n",
       "  'i',\n",
       "  'got',\n",
       "  'this',\n",
       "  'in',\n",
       "  'addition',\n",
       "  'to',\n",
       "  'the',\n",
       "  'root',\n",
       "  'beer',\n",
       "  'extract',\n",
       "  'i',\n",
       "  'ordered',\n",
       "  'which',\n",
       "  'was',\n",
       "  'good',\n",
       "  'and',\n",
       "  'made',\n",
       "  'some',\n",
       "  'cherry',\n",
       "  'soda',\n",
       "  'the',\n",
       "  'flavor',\n",
       "  'is',\n",
       "  'very',\n",
       "  'medicinal'],\n",
       " ['great',\n",
       "  'taffy',\n",
       "  'at',\n",
       "  'a',\n",
       "  'great',\n",
       "  'price',\n",
       "  'there',\n",
       "  'was',\n",
       "  'a',\n",
       "  'wide',\n",
       "  'assortment',\n",
       "  'of',\n",
       "  'yummy',\n",
       "  'taffy',\n",
       "  'delivery',\n",
       "  'was',\n",
       "  'very',\n",
       "  'quick',\n",
       "  'if',\n",
       "  'your',\n",
       "  'a',\n",
       "  'taffy',\n",
       "  'lover',\n",
       "  'this',\n",
       "  'is',\n",
       "  'a',\n",
       "  'deal']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = [re.sub(r'[^\\w\\s]','', x).lower().split() for x in text]\n",
    "text2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = text2[:200000]\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callback(CallbackAny2Vec):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        elif self.epoch % 10 == 0:        \n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss - self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = Word2Vec(size = 300,        # embedding size\n",
    "               window = 15,       # max distance between target and context word \n",
    "               min_count = 2,     # ignore words with freq lower than this\n",
    "               workers = 4,       # threads\n",
    "               sg = 1,            # 1 for skip-gram, 0 for CBOW\n",
    "               negative = 5,      # negative sampling number\n",
    "               sample = 1e-5)     # hyper-parameter to downsample high freq word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.build_vocab(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 19041792.0\n",
      "Loss after epoch 10: 705472.0\n",
      "Loss after epoch 20: 734552.0\n",
      "Loss after epoch 30: 657536.0\n",
      "Loss after epoch 40: 600680.0\n",
      "Loss after epoch 50: 526160.0\n",
      "Loss after epoch 60: 449072.0\n",
      "Loss after epoch 70: 369360.0\n",
      "Loss after epoch 80: 286224.0\n",
      "Loss after epoch 90: 219496.0\n",
      "Loss after epoch 100: 168920.0\n",
      "Time cost: 1710.249447107315\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "w2v.train(tokens, total_examples=w2v.corpus_count, epochs=101,\n",
    "         report_delay=1, compute_loss=True, callbacks=[Callback()])\n",
    "end = time.time()\n",
    "\n",
    "print('Time cost: ' + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.save('w2v(amazon).model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 66720\n"
     ]
    }
   ],
   "source": [
    "reloaded_w2c = Word2Vec.load('w2v(amazon).model')\n",
    "words = list(reloaded_w2c.wv.vocab)\n",
    "print('Vocab size: ' + str(len(words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'have',\n",
       " 'bought',\n",
       " 'several',\n",
       " 'of',\n",
       " 'the',\n",
       " 'vitality',\n",
       " 'canned',\n",
       " 'dog',\n",
       " 'food',\n",
       " 'products',\n",
       " 'and',\n",
       " 'found',\n",
       " 'them',\n",
       " 'all',\n",
       " 'to',\n",
       " 'be',\n",
       " 'good',\n",
       " 'quality',\n",
       " 'product',\n",
       " 'looks',\n",
       " 'more',\n",
       " 'like',\n",
       " 'a',\n",
       " 'stew',\n",
       " 'than',\n",
       " 'processed',\n",
       " 'meat',\n",
       " 'it',\n",
       " 'smells',\n",
       " 'better',\n",
       " 'my',\n",
       " 'labrador',\n",
       " 'is',\n",
       " 'finicky',\n",
       " 'she',\n",
       " 'appreciates',\n",
       " 'this',\n",
       " 'most',\n",
       " 'arrived',\n",
       " 'labeled',\n",
       " 'as',\n",
       " 'jumbo',\n",
       " 'salted',\n",
       " 'peanutsthe',\n",
       " 'peanuts',\n",
       " 'were',\n",
       " 'actually',\n",
       " 'small',\n",
       " 'sized',\n",
       " 'unsalted',\n",
       " 'not',\n",
       " 'sure',\n",
       " 'if',\n",
       " 'was',\n",
       " 'an',\n",
       " 'error',\n",
       " 'or',\n",
       " 'vendor',\n",
       " 'intended',\n",
       " 'represent',\n",
       " 'confection',\n",
       " 'that',\n",
       " 'has',\n",
       " 'been',\n",
       " 'around',\n",
       " 'few',\n",
       " 'centuries',\n",
       " 'light',\n",
       " 'pillowy',\n",
       " 'citrus',\n",
       " 'gelatin',\n",
       " 'with',\n",
       " 'nuts',\n",
       " 'in',\n",
       " 'case',\n",
       " 'filberts',\n",
       " 'cut',\n",
       " 'into',\n",
       " 'tiny',\n",
       " 'squares',\n",
       " 'then',\n",
       " 'liberally',\n",
       " 'coated',\n",
       " 'powdered',\n",
       " 'sugar',\n",
       " 'mouthful',\n",
       " 'heaven',\n",
       " 'too',\n",
       " 'chewy',\n",
       " 'very',\n",
       " 'flavorful',\n",
       " 'highly',\n",
       " 'recommend',\n",
       " 'yummy',\n",
       " 'treat',\n",
       " 'you',\n",
       " 'are',\n",
       " 'familiar',\n",
       " 'story']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 similar words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('have', 0.7322862148284912),\n",
       " ('been', 0.6838940382003784),\n",
       " ('ive', 0.6773158311843872)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 'several'\n",
    "print('Top 3 similar words:')\n",
    "reloaded_w2c.wv.most_similar(positive = w1, topn = 3)\n",
    "# need more training, need remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between A and B:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.77047503"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Similarity between A and B:')\n",
    "reloaded_w2c.wv.similarity(w1='better', w2='good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "\n",
    "def reduce_dimensions(model):\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    vectors = [] # positions in vector space\n",
    "    labels = [] # keep track of words to label our data again later\n",
    "    for word in model.wv.vocab:\n",
    "        vectors.append(model.wv[word])\n",
    "        labels.append(word)\n",
    "\n",
    "    # convert both lists into numpy vectors for reduction\n",
    "    vectors = np.asarray(vectors)\n",
    "    #labels = np.asarray(labels)\n",
    "\n",
    "    # reduce using t-SNE\n",
    "    vectors = np.asarray(vectors)\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "    return x_vals, y_vals, labels\n",
    "\n",
    "\n",
    "x_vals, y_vals, labels = reduce_dimensions(reloaded_w2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def plot_with_matplotlib(x_vals, y_vals, labels):\n",
    "\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(x_vals, y_vals)\n",
    "\n",
    "    #\n",
    "    # Label randomly subsampled 25 data points\n",
    "    #\n",
    "    \n",
    "    \n",
    "    indices = list(range(len(labels)))\n",
    "    #selected_indices = random.sample(indices, 25)\n",
    "    selected_indices=[]\n",
    "    index = labels.index(\"cell\")\n",
    "    selected_indices.append(index)\n",
    "    index = labels.index(\"phone\")\n",
    "    selected_indices.append(index)\n",
    "    index = labels.index(\"noise\")\n",
    "    selected_indices.append(index)\n",
    "    index = labels.index(\"cancellation\")\n",
    "    selected_indices.append(index)\n",
    "    index = labels.index(\"charger\")\n",
    "    selected_indices.append(index)\n",
    "    index = labels.index(\"charge\")\n",
    "    selected_indices.append(index)\n",
    "    index = labels.index(\"poor\")\n",
    "    selected_indices.append(index)\n",
    "    index = labels.index(\"bad\")\n",
    "    selected_indices.append(index)\n",
    "    \n",
    "    \n",
    "    for i in selected_indices:\n",
    "        plt.annotate(labels[i], (x_vals[i], y_vals[i]))\n",
    "\n",
    "\n",
    "\n",
    "plot_function = plot_with_matplotlib\n",
    "\n",
    "\n",
    "plot_function(x_vals, y_vals, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
