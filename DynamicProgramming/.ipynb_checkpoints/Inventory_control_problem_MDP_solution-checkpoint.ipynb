{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single product stochastic inventory control problem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the problem of inventory control of a single product over a time horizon of $T = 3$ periods. The manager objective is to maximize his or her profit over the decision-making horizon, i.e. sales revenue $f(x) = 8x$ less inventory holding $h(x)=x$ and ordering costs $c(x)=K+2x$, where $K=4$ represents the fixed cost. The inventory level has capacity of $C=3$ units. Demand $D$ for the product is random with a known probability distribution: $p_0=\\mathbb{P}(D_t = 0)=0.25, p_1=\\mathbb{P}(D_t = 1)=0.5, p_0 = \\mathbb{P}(D_t = 2)=0.25, \\forall t =\\overline{1, T}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%latex\n",
    "\n",
    "Let us formulate the problem as a Markov decision process:\n",
    "    \n",
    "\\begin{itemize}\n",
    "   \\item \\textbf{Decision epochs:} $t = \\overline{1, T}$\n",
    "  \t\n",
    "   \\item \\textbf{States $s_t$:} the amount of inventory on hand at the start of each period $t$ \n",
    "     \\begin{itemize}\n",
    "            \\item State space: $s_t \\in \\{0,1,\\dots, C\\}$\n",
    "       \\end{itemize}\n",
    "    \\item \\textbf{Action $a_t$:}  the amount of additional stock to order in period  $t$\n",
    "     \\begin{itemize}\n",
    "        \\item Action space: $ A_s = \\{0, 1, \\dots, C-s\\}$\n",
    "      \\end{itemize}\n",
    "    \\item \\textbf{System dynamics:} transition probabilities\n",
    "       \t\t$$ p_t(j|s,a) = \\left\\{\n",
    "    \t\t\\begin{array}{rl}\n",
    "    \t\t0, & \\text{if } s+a<j\\leq C\\\\\n",
    "    \t\tp_{s+a-j}, & \\text{if } 0<j\\leq s+a\\leq C \\\\ \n",
    "            q_{s+a}, & \\text{if } j=0 \\text{ and }  s+a\\leq C \\\\ \\end{array}\n",
    "    \t\t\\right.\n",
    "    \t\t$$  \n",
    "    where $q_{s+a}$ denotes the probability that the demand in period $t$ exceeds $s+a$ units.\n",
    "   \n",
    "   \\end{itemize}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the backward induction algorithm step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "    table.dataframe td, table.dataframe th {\n",
    "        border-style: solid;\n",
    "    }\n",
    "</style>\n",
    "\n",
    "\\textbf{Step 0:} Initialize and preprocess the problem parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transition probabilities:\n",
    "\n",
    "|s+a \\ j |0 | 1 | 2 | 3 |\n",
    "| --- | --- | --- | --- | --- | \n",
    "| 0 | 1 \t|0 | 0 | 0|\n",
    "|1 | 0.75 | 0.25 | 0 | 0|\n",
    "|2 | 0.25 | 0.5| 0.25 | 0|\n",
    "|3 | 0 | 0.25| 0.5 | 0.25 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "K = 4\n",
    "T = 3\n",
    "C = 3 \n",
    "states = [0, 1, 2 ,3]\n",
    "proba = [0.25, 0.5, 0.25]\n",
    "trans_proba = np.array([[1, 0, 0, 0],\n",
    "[0.75, 0.25, 0, 0],\n",
    "[0.25, 0.5, 0.25, 0],\n",
    "[0, 0.25, 0.5, 0.25]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implement cost functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 8*x\n",
    "\n",
    "def h(x):\n",
    "    return x\n",
    "\n",
    "def c(x):\n",
    "    if x > 0:\n",
    "        return K + 2*x\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def expected_f(u):\n",
    "    sum = 0\n",
    "    q = 0\n",
    "    for i in range(u, T):\n",
    "        q = q + proba[i]\n",
    "    for i in range(u):\n",
    "        sum = sum + f(i)*proba[i]\n",
    "    return  sum + f(u)*q\n",
    "\n",
    "def r(s, a):\n",
    "    return expected_f(s+a) - h(s+a) - c(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\textbf{Step 4:} Set $t = 4$ and $v_4^*(s) = r_4(s) = 0, \\forall s$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_best_4 = np.zeros(len(states)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\textbf{Step 3:} Since $ t > 1$, continue. Set $t=3$ and calculate $v_3^*$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_best_3 = np.zeros(len(states)) \n",
    "a_best_3 = np.zeros(len(states)) \n",
    "\n",
    "for s in states:\n",
    "    for a in range(0, C-s+1):\n",
    "        if v_best_3[s] < r(s, a):\n",
    "            v_best_3[s] = r(s, a)\n",
    "            a_best_3[s]  = a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution values of optimal equalities are:  [0. 5. 6. 5.]\n",
      "Maximizing action for each state are:  [0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('Solution values of optimal equalities are: ', v_best_3)\n",
    "print('Maximizing action for each state are: ', a_best_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\textbf{Step 2:} Since $t > 1$, continue. Set $t=2$ and calculate $v_2^*$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_best_2 = np.zeros(len(states)) \n",
    "a_best_2 = np.zeros(len(states)) \n",
    "\n",
    "for s in states:\n",
    "    for a in range(0, C-s+1):\n",
    "        second_term = 0\n",
    "        for j in range(0, len(states)):\n",
    "            second_term = second_term + trans_proba[s+a, j]*v_best_3[j]\n",
    "        if v_best_2[s] < r(s, a) + second_term:\n",
    "            v_best_2[s] = r(s, a) + second_term\n",
    "            a_best_2[s]  = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution values of optimal equalities are:  [ 2.    6.25 10.   10.5 ]\n",
      "Maximizing action for each state are:  [2. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('Solution values of optimal equalities are: ', v_best_2)\n",
    "print('Maximizing action for each state are: ', a_best_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\textbf{Step 1:} Since $t > 1$, continue. Set $t=1$ and calculate $v_1^*$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_best_1 = np.zeros(len(states)) \n",
    "a_best_1 = np.zeros(len(states)) \n",
    "\n",
    "for s in states:\n",
    "    for a in range(0, C-s+1):\n",
    "        second_term = 0\n",
    "        for j in range(0, len(states)):\n",
    "            second_term = second_term + trans_proba[s+a, j]*v_best_2[j]\n",
    "        if v_best_1[s] < r(s, a) + second_term:\n",
    "            v_best_1[s] = r(s, a) + second_term\n",
    "            a_best_1[s]  = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution values of optimal equalities are:  [ 4.1875  8.0625 12.125  14.1875]\n",
      "Maximizing action for each state are:  [3. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('Solution values of optimal equalities are: ', v_best_1)\n",
    "print('Maximizing action for each state are: ', a_best_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\textbf{Step 1:} Since $t = 1$, stop. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm yields the optimal expected total reward function $v_4^*(s)$ and the\n",
    "optimal policy $\\pi^* = (d_1^*(s), d_2^*(s), d_3^*(s))$, given below. Note in this example that the optimal policy is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "optimal_policy = pd.DataFrame(columns = ['state', 'd_1', 'd_2', 'd_3', 'exp_tot_reward'])\n",
    "optimal_policy['state'] = states\n",
    "optimal_policy['d_1'] = a_best_1\n",
    "optimal_policy['d_2'] = a_best_2\n",
    "optimal_policy['d_3'] = a_best_3\n",
    "optimal_policy['exp_tot_reward'] = v_best_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   state  d_1  d_2  d_3  exp_tot_reward\n",
      "0      0  3.0  2.0  0.0          4.1875\n",
      "1      1  0.0  0.0  0.0          8.0625\n",
      "2      2  0.0  0.0  0.0         12.1250\n",
      "3      3  0.0  0.0  0.0         14.1875\n"
     ]
    }
   ],
   "source": [
    "print(optimal_policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
