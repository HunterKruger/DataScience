{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import en_core_web_md\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from gensim.models.coherencemodel import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568438 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('AmazonReviews.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users:\n",
      "256059\n",
      "Unique products:\n",
      "74258\n"
     ]
    }
   ],
   "source": [
    "print('Unique users:')\n",
    "print(len(df.groupby('UserId')))\n",
    "print('Unique products:')\n",
    "print(len(df.groupby('ProductId')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    delect_dict = {special_char: '' for special_char in string.punctuation}\n",
    "    delect_dict[' '] = ' ' # ??\n",
    "    table = str.maketrans(delect_dict)  # dict, get keys' ASCII\n",
    "    text = text.translate(table)  # turn key to its value\n",
    "    text = text.split()  # tokenize\n",
    "    text = ' '.join([w for w in text if (not w.isdigit() and len(w)>3)]) # remove digits, word's len>3\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    363111\n",
      "4     80655\n",
      "1     52264\n",
      "3     42638\n",
      "2     29743\n",
      "Name: Score, dtype: int64\n",
      "568411\n",
      "2234\n"
     ]
    }
   ],
   "source": [
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "df['Word_count'] = df['Text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print(df['Score'].value_counts())\n",
    "print(len(df))\n",
    "\n",
    "max_text_len = df['Word_count'].max()\n",
    "print(max_text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373281\n",
      "5    233648\n",
      "4     53413\n",
      "1     36230\n",
      "3     29080\n",
      "2     20910\n",
      "Name: Score, dtype: int64\n",
      "373281\n"
     ]
    }
   ],
   "source": [
    "condition = (df['Word_count']<100) & (df['Word_count']>=20)\n",
    "df_short = df[condition]\n",
    "print(len(df_short))\n",
    "\n",
    "print(df_short['Score'].value_counts())\n",
    "print(len(df_short))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "df_sampled = df_short.groupby('Score').apply(lambda x: x.sample(n=20000)).reset_index(drop=True)\n",
    "print(len(df_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = stopwords.words('english')\n",
    "    text = text.split(' ')\n",
    "    text = ' '.join([w for w in text if w not in stop_words])\n",
    "    return text\n",
    "\n",
    "df_sampled['Text'] = df_sampled['Text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['many', 'different', 'item', 'amazoncom', 'year', 'review', 'today', 'rancher', 'green', 'apple', 'one', 'gift', 'husband', 'jolly', 'rancher', 'candy', 'broken', 'crushed', 'dust', 'slivereen', 'seller', 'handling', 'box']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md', disable = ['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts, allowed_postags = ['NOUN', 'ADJ']):\n",
    "    output = []\n",
    "    for sentence in texts:\n",
    "        doc = nlp(sentence)\n",
    "        output.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return output\n",
    "\n",
    "text_list = df_sampled['Text'].tolist()\n",
    "tokens = lemmatization(text_list)\n",
    "print(tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokens)\n",
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "lda_model = LDA(corpus = doc_term_matrix, \n",
    "                id2word = dictionary, \n",
    "                num_topics = 10, \n",
    "                random_state = 100, \n",
    "                chunksize = 100, \n",
    "                passes = 50,\n",
    "                iterations = 100\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Perplexity:') # the lower the better\n",
    "# Perp = P(w1w2...wn)^(1/n)\n",
    "print(lda_model.log_perplexity(doc_term_matrix), total_docs = 10000)\n",
    "coherence_model_lda = CoherenceModel(model = lda_model, texts = tokens, dictionary = dictionary, coherence = 'c_v')\n",
    "print('Coherence:') # the higher the better\n",
    "print(coherence_model_lda.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
