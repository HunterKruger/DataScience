{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:35:23.553998Z",
     "start_time": "2020-04-14T11:35:21.808034Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:35:23.687554Z",
     "start_time": "2020-04-14T11:35:23.557154Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train_test_data/train.csv')\n",
    "test = pd.read_csv('../data/train_test_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:35:23.731759Z",
     "start_time": "2020-04-14T11:35:23.696626Z"
    }
   },
   "outputs": [],
   "source": [
    "to_drop=['Hillshade_3pm', 'Vertical_Distance_To_Hydrology','Id','Soil_Type7','Soil_Type15']\n",
    "train.drop(to_drop,axis=1,inplace=True)\n",
    "test.drop(to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:35:23.787798Z",
     "start_time": "2020-04-14T11:35:23.740851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elevation',\n",
       " 'Aspect',\n",
       " 'Slope',\n",
       " 'Horizontal_Distance_To_Hydrology',\n",
       " 'Horizontal_Distance_To_Roadways',\n",
       " 'Hillshade_9am',\n",
       " 'Hillshade_Noon',\n",
       " 'Horizontal_Distance_To_Fire_Points']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_col = []\n",
    "for col in train.columns:\n",
    "    if train[col].nunique()>2 and col!='Cover_Type':\n",
    "        num_col.append(col)\n",
    "        \n",
    "num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:35:23.904015Z",
     "start_time": "2020-04-14T11:35:23.791829Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_outliers_tukey(feature):\n",
    "    q1 = np.percentile(feature, 25)\n",
    "    q3 = np.percentile(feature, 75)\n",
    "    iqr = q3-q1\n",
    "    upbound = q3+1.5*iqr\n",
    "    downbound = q1 - 1.5*iqr\n",
    "    outlier_indices = list(\n",
    "        feature.index[(feature > upbound) | (feature < downbound)])\n",
    "    outlier_values = list(feature[outlier_indices])\n",
    "    return outlier_indices, outlier_values\n",
    "\n",
    "# find outlier by 1.5IQR, then impute with median in train set, do not touch test set\n",
    "for col in num_col:\n",
    "    outlier_indices_train, outlier_values_train = find_outliers_tukey(train[col])\n",
    "    train.loc[outlier_indices_train, col] = train[col].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:35:23.961673Z",
     "start_time": "2020-04-14T11:35:23.906257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Horizontal_Distance_To_Fire_Points']\n",
      "['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon', 'Horizontal_Distance_To_Fire_Points']\n"
     ]
    }
   ],
   "source": [
    "pos_num_col=[] # choose features whose data all >= 0, then do skewness test, log1p\n",
    "for col in num_col:\n",
    "    if (train[train[col]<0].shape[0])==0 and (test[test[col]<0].shape[0])==0:\n",
    "        pos_num_col.append(col)\n",
    "print(pos_num_col)\n",
    "print(num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:35:24.063851Z",
     "start_time": "2020-04-14T11:35:23.967254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness for Horizontal_Distance_To_Hydrology: 0.8324195210682085\n",
      "Skewness for Horizontal_Distance_To_Roadways: 1.0004715097062213\n",
      "Skewness for Hillshade_9am: -0.7393861768856743\n",
      "Skewness for Hillshade_Noon: -0.5496178397165092\n",
      "Skewness for Horizontal_Distance_To_Fire_Points: 0.8027994190907131\n",
      "---------------------------\n",
      "Skewness for Horizontal_Distance_To_Roadways: 1.0004715097062213\n",
      "Skewness for Horizontal_Distance_To_Roadways: -0.8998026883390026\n",
      "---------------------------\n",
      "Skewness for Horizontal_Distance_To_Hydrology: 0.8324195210682085\n",
      "Skewness for Hillshade_9am: -0.7393861768856743\n",
      "Skewness for Hillshade_Noon: -0.5496178397165092\n",
      "Skewness for Horizontal_Distance_To_Fire_Points: 0.8027994190907131\n",
      "---------------------------\n",
      "Skewness for Hillshade_9am: -0.7393861768856743\n",
      "Skewness for Hillshade_9am: -0.4801426168943799\n",
      "---------------------------\n",
      "Skewness for Horizontal_Distance_To_Hydrology: 0.8324195210682085\n",
      "Skewness for Hillshade_Noon: -0.5496178397165092\n",
      "Skewness for Horizontal_Distance_To_Fire_Points: 0.8027994190907131\n",
      "---------------------------\n",
      "Skewness for Horizontal_Distance_To_Hydrology: 0.8324195210682085\n",
      "Skewness for Horizontal_Distance_To_Hydrology: -0.23362142179084902\n",
      "Skewness for Horizontal_Distance_To_Fire_Points: 0.8027994190907131\n",
      "Skewness for Horizontal_Distance_To_Fire_Points: 0.10823037032418481\n",
      "---------------------------\n",
      "Skewness for Hillshade_Noon: -0.5496178397165092\n"
     ]
    }
   ],
   "source": [
    "# Handle skewness\n",
    "\n",
    "for col in pos_num_col:\n",
    "    if abs(train[col].skew()) > 0.5:\n",
    "        print(\"Skewness for \"+str(col)+\": \" + str(train[col].skew()))        \n",
    "print('---------------------------')            \n",
    "for col in pos_num_col:        # log(1+x)\n",
    "    if abs(train[col].skew()) > 0.5 and abs(np.log1p(train[col]).skew())<abs(train[col].skew()):\n",
    "        print(\"Skewness for \"+str(col)+\": \" + str(train[col].skew()))\n",
    "        train[col] = np.log1p(train[col])\n",
    "        test[col] = np.log1p(test[col])\n",
    "        print(\"Skewness for \"+str(col)+\": \" + str(train[col].skew()))\n",
    "        pos_num_col.remove(col)          \n",
    "print('---------------------------')   \n",
    "for col in pos_num_col:\n",
    "    if abs(train[col].skew()) > 0.5:\n",
    "        print(\"Skewness for \"+str(col)+\": \" + str(train[col].skew()))      \n",
    "print('---------------------------')   \n",
    "for col in pos_num_col:     # x square\n",
    "    if abs(train[col].skew()) > 0.5 and abs(np.square(train[col]).skew())<abs(train[col].skew()):\n",
    "        print(\"Skewness for \"+str(col)+\": \" + str(train[col].skew()))\n",
    "        train[col] = np.square(train[col])\n",
    "        test[col] = np.square(test[col])\n",
    "        print(\"Skewness for \"+str(col)+\": \" + str(train[col].skew()))\n",
    "        pos_num_col.remove(col)   \n",
    "print('---------------------------')   \n",
    "for col in pos_num_col:\n",
    "    if abs(train[col].skew()) > 0.5:\n",
    "        print(\"Skewness for \"+str(col)+\": \" + str(train[col].skew()))\n",
    "print('---------------------------')   \n",
    "for col in pos_num_col:        # x square root\n",
    "    if abs(train[col].skew()) > 0.5 and abs(np.sqrt(train[col]).skew())<abs(train[col].skew()):\n",
    "        print(\"Skewness for \"+str(col)+\": \" + str(train[col].skew()))\n",
    "        train[col] = np.sqrt(train[col])\n",
    "        test[col] = np.sqrt(test[col])\n",
    "        print(\"Skewness for \"+str(col)+\": \" + str(train[col].skew()))\n",
    "        pos_num_col.remove(col)   \n",
    "print('---------------------------')   \n",
    "for col in pos_num_col:\n",
    "    if abs(train[col].skew()) > 0.5:\n",
    "        print(\"Skewness for \"+str(col)+\": \" + str(train[col].skew()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:35:24.089496Z",
     "start_time": "2020-04-14T11:35:24.068801Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_col = [] \n",
    "for col in train.columns:\n",
    "    if train[col].nunique()==2:\n",
    "        cat_col.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:35:24.135077Z",
     "start_time": "2020-04-14T11:35:24.092554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/scaler.m']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling numerical features\n",
    "ss = StandardScaler()\n",
    "train_num = ss.fit_transform(train[num_col])\n",
    "train_num = pd.DataFrame(train_num,columns=num_col)\n",
    "test_num = ss.transform(test[num_col])\n",
    "test_num = pd.DataFrame(test_num,columns=num_col)\n",
    "joblib.dump(ss, '../models/scaler.m') # save scaler model as scaler.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:35:24.163235Z",
     "start_time": "2020-04-14T11:35:24.137941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12096, 50), (3024, 50))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.concat([train_num,train[cat_col]],axis=1)\n",
    "X_test = pd.concat([test_num,test[cat_col]],axis=1)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:35:24.187088Z",
     "start_time": "2020-04-14T11:35:24.176206Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = train['Cover_Type']\n",
    "y_test = test['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:35:24.338344Z",
     "start_time": "2020-04-14T11:35:24.193476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12096, 29), (3024, 29))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.99)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "joblib.dump(pca, '../models/pca.m') # save pca model as pca.m\n",
    "X_train_pca.shape,X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:35:25.941063Z",
     "start_time": "2020-04-14T11:35:24.343010Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train_pca).to_csv('../data/featured_data_PCA/X_train.csv',index=False)\n",
    "pd.DataFrame(X_test_pca).to_csv('../data/featured_data_PCA/X_test.csv',index=False)\n",
    "pd.DataFrame(y_train).to_csv('../data/featured_data_PCA/y_train.csv',index=False)\n",
    "pd.DataFrame(y_test).to_csv('../data/featured_data_PCA/y_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-14T11:35:26.610036Z",
     "start_time": "2020-04-14T11:35:25.943382Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train).to_csv('../data/featured_data/X_train.csv',index=False)\n",
    "pd.DataFrame(X_test).to_csv('../data/featured_data/X_test.csv',index=False)\n",
    "pd.DataFrame(y_train).to_csv('../data/featured_data/y_train.csv',index=False)\n",
    "pd.DataFrame(y_test).to_csv('../data/featured_data/y_test.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
