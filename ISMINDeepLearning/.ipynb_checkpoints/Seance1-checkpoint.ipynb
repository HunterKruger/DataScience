{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data: train, test\n",
    "(ox_train,oy_train),(x_test,y_test)=tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ox_train.shape,oy_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data:  train->train,valid\n",
    "x_train,x_valid,y_train,y_valid=train_test_split(ox_train,oy_train,test_size=0.2,random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 28, 28), (48000,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max(),y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "\n",
    "x_avg = np.mean(x_train,axis=0,keepdims=True)  # the axis contains 48000 \n",
    "x_train = x_train-x_avg\n",
    "x_norm = np.max(np.abs(x_train),axis=0,keepdims=True)\n",
    "x_norm[x_norm==0]=1 # when x_norm = 0\n",
    "x_train = x_train/x_norm\n",
    "\n",
    "x_valid=(x_valid-x_avg)/x_norm\n",
    "x_test=(x_test-x_avg)/x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 150)               117750    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 60)                9060      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                610       \n",
      "=================================================================\n",
      "Total params: 127,420\n",
      "Trainable params: 127,420\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "\n",
    "lin = tf.keras.layers.Input(shape=(28,28))\n",
    "lact = lin\n",
    "lact = tf.keras.layers.Flatten()(lact)  \n",
    "lact = tf.keras.layers.Dense(150,activation='relu')(lact)\n",
    "lact = tf.keras.layers.Dense(60,activation='relu')(lact)\n",
    "lact = tf.keras.layers.Dense(10,activation='softmax')(lact)      \n",
    "lout = lact\n",
    "\n",
    "model0 = tf.keras.Model(lin,lout)\n",
    "model0.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.compile(tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              tf.keras.losses.CategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Utilities\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "lin = tf.keras.layers.Input(shape=(10,))  # 10 neurons for input layer\n",
    "lout = tf.keras.layers.Dense(1,use_bias=True,activation='linear')(lin)      \n",
    "# connect to input layer   # 1 neuron for output layer\n",
    "model1 = tf.keras.Model(lin,lout)\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 11\n",
      "Trainable params: 11\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "lin = tf.keras.layers.Input(shape=(10,))  \n",
    "lout = tf.keras.layers.Dense(1,use_bias=True,activation='sigmoid')(lin) \n",
    "# connect to input layer  # binary-classification  # 1 neuron for output layer\n",
    "model2 = tf.keras.Model(lin,lout)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 55\n",
      "Trainable params: 55\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# logistic regression\n",
    "lin = tf.keras.layers.Input(shape=(10,))  \n",
    "lout = tf.keras.layers.Dense(5,use_bias=True,activation='softmax')(lin) \n",
    "# connect to input layer  # 5-class mulit-classification  # 5 neurons for output layer\n",
    "model3 = tf.keras.Model(lin,lout)\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Softmax (TensorF [(None, 5)]               0         \n",
      "=================================================================\n",
      "Total params: 55\n",
      "Trainable params: 55\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# logistic regression # the same as previous\n",
    "lin = tf.keras.layers.Input(shape=(10,))  \n",
    "lact = tf.keras.layers.Dense(5,use_bias=True)(lin) \n",
    "# connect to input layer  # 5-class mulit-classification  # 5 neurons for output layer\n",
    "lout=tf.keras.activations.softmax(lact)\n",
    "model4 = tf.keras.Model(lin,lout)\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
